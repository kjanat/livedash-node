# LiveDash Node Migration Guide v2.0.0

## Overview

This guide provides step-by-step instructions for migrating LiveDash Node to version 2.0.0, which introduces tRPC implementation and OpenAI Batch API integration for improved performance and cost efficiency.

## üöÄ New Features

### tRPC Implementation
- **Type-safe APIs**: End-to-end TypeScript safety from client to server
- **Improved Performance**: Optimized query batching and caching
- **Better Developer Experience**: Auto-completion and type checking
- **Simplified Authentication**: Integrated with existing NextAuth.js setup

### OpenAI Batch API Integration
- **50% Cost Reduction**: Batch processing reduces OpenAI API costs by half
- **Enhanced Rate Limiting**: Better throughput management
- **Improved Reliability**: Automatic retry mechanisms and error handling
- **Automated Processing**: Background batch job lifecycle management

### Enhanced Security & Performance
- **Rate Limiting**: In-memory rate limiting for all authentication endpoints
- **Input Validation**: Comprehensive Zod schemas for all user inputs
- **Performance Monitoring**: Built-in metrics collection and monitoring
- **Database Optimizations**: New indexes and query optimizations

## üìã Pre-Migration Checklist

### System Requirements
- [ ] Node.js 18+ installed
- [ ] PostgreSQL 13+ database
- [ ] `pg_dump` and `pg_restore` utilities available
- [ ] Git repository with clean working directory
- [ ] OpenAI API key (for production)
- [ ] Sufficient disk space for backups (at least 2GB)

### Environment Preparation
- [ ] Review current environment variables
- [ ] Ensure database connection is working
- [ ] Verify all tests are passing
- [ ] Create a backup of your current deployment
- [ ] Notify team members of planned downtime

## üîß Migration Process

### Phase 1: Pre-Migration Setup

#### 1.1 Install Migration Tools
```bash
# Ensure you have the latest dependencies
pnpm install

# Verify migration scripts are available
pnpm migration:validate-env --help
```

#### 1.2 Run Pre-Deployment Checks
```bash
# Run comprehensive pre-deployment validation
pnpm migration:pre-check

# This will validate:
# - Environment configuration
# - Database connection and schema
# - Dependencies
# - File system permissions
# - OpenAI API access
# - tRPC infrastructure readiness
```

#### 1.3 Environment Configuration
```bash
# Generate new environment variables
pnpm migration:migrate-env

# Review the generated files:
# - .env.migration.template
# - ENVIRONMENT_MIGRATION_GUIDE.md
```

**Add these new environment variables to your `.env.local`:**

```bash
# tRPC Configuration
TRPC_ENDPOINT_URL="http://localhost:3000/api/trpc"
TRPC_BATCH_TIMEOUT="30000"
TRPC_MAX_BATCH_SIZE="100"

# Batch Processing Configuration
BATCH_PROCESSING_ENABLED="true"
BATCH_CREATE_INTERVAL="*/5 * * * *"
BATCH_STATUS_CHECK_INTERVAL="*/2 * * * *"
BATCH_RESULT_PROCESSING_INTERVAL="*/1 * * * *"
BATCH_MAX_REQUESTS="1000"
BATCH_TIMEOUT_HOURS="24"

# Security & Performance
RATE_LIMIT_WINDOW_MS="900000"
RATE_LIMIT_MAX_REQUESTS="100"
PERFORMANCE_MONITORING_ENABLED="true"
METRICS_COLLECTION_INTERVAL="60"

# Migration Settings (temporary)
MIGRATION_MODE="production"
MIGRATION_BACKUP_ENABLED="true"
MIGRATION_ROLLBACK_ENABLED="true"
```

### Phase 2: Database Migration

#### 2.1 Create Database Backup
```bash
# Create full database backup
pnpm migration:backup

# Verify backup was created
pnpm migration:backup list
```

#### 2.2 Validate Database Schema
```bash
# Validate current database state
pnpm migration:validate-db
```

#### 2.3 Apply Database Migrations
```bash
# Run Prisma migrations
pnpm prisma:migrate

# Apply additional schema changes
psql $DATABASE_URL -f scripts/migration/01-schema-migrations.sql

# Verify migration success
pnpm migration:validate-db
```

### Phase 3: Application Deployment

#### 3.1 Dry Run Deployment
```bash
# Test deployment process without making changes
pnpm migration:deploy:dry-run
```

#### 3.2 Full Deployment
```bash
# Execute full deployment
pnpm migration:deploy

# This will:
# 1. Apply database schema changes
# 2. Deploy new application code
# 3. Restart services with minimal downtime
# 4. Enable tRPC endpoints progressively
# 5. Activate batch processing system
# 6. Run post-deployment validation
```

### Phase 4: Post-Migration Validation

#### 4.1 System Health Check
```bash
# Run comprehensive health checks
pnpm migration:health-check

# Generate detailed health report
pnpm migration:health-report
```

#### 4.2 Feature Validation
```bash
# Test tRPC endpoints
pnpm exec tsx scripts/migration/trpc-endpoint-tests.ts

# Test batch processing system
pnpm exec tsx scripts/migration/batch-processing-tests.ts

# Run full test suite
pnpm migration:test
```

## üîÑ Rollback Procedure

If issues occur during migration, you can rollback using these steps:

### Automatic Rollback
```bash
# Quick rollback (if migration failed)
pnpm migration:rollback

# Dry run rollback to see what would happen
pnpm migration:rollback:dry-run
```

### Manual Rollback Steps
1. **Stop the application**
2. **Restore database from backup**
3. **Revert to previous code version**
4. **Restart services**
5. **Verify system functionality**

### Rollback Commands
```bash
# Create rollback snapshot (before migration)
pnpm migration:rollback:snapshot

# Restore from specific backup
pnpm migration:rollback --backup /path/to/backup.sql

# Skip database rollback (code only)
pnpm migration:rollback --no-database
```

## üìä Monitoring and Validation

### Post-Migration Monitoring

#### 1. Application Health
```bash
# Check system health every hour for the first day
*/60 * * * * cd /path/to/livedash && pnpm migration:health-check

# Monitor logs for errors
tail -f logs/migration.log
```

#### 2. tRPC Performance
- Monitor response times for tRPC endpoints
- Check error rates in application logs
- Verify type safety is working correctly

#### 3. Batch Processing
- Monitor batch job completion rates
- Check OpenAI API cost reduction
- Verify AI processing pipeline functionality

### Key Metrics to Monitor

#### Performance Metrics
- **Response Times**: tRPC endpoints should respond within 500ms
- **Database Queries**: Complex queries should complete within 1s
- **Memory Usage**: Should remain below 80% of allocated memory
- **CPU Usage**: Process should remain responsive

#### Business Metrics
- **AI Processing Cost**: Should see ~50% reduction in OpenAI costs
- **Processing Throughput**: Batch processing should handle larger volumes
- **Error Rates**: Should remain below 1% for critical operations
- **User Experience**: No degradation in dashboard performance

## üõ† Troubleshooting

### Common Issues and Solutions

#### tRPC Endpoints Not Working
```bash
# Check if tRPC files exist
ls -la app/api/trpc/[trpc]/route.ts
ls -la server/routers/_app.ts

# Verify tRPC router exports
pnpm exec tsx -e "import('./server/routers/_app').then(m => console.log(Object.keys(m)))"

# Test endpoints manually
curl -X POST http://localhost:3000/api/trpc/auth.getSession \
  -H "Content-Type: application/json" \
  -d '{"json": null}'
```

#### Batch Processing Issues
```bash
# Check batch processing components
pnpm exec tsx scripts/migration/batch-processing-tests.ts

# Verify OpenAI API access
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
  https://api.openai.com/v1/models

# Check batch job status
psql $DATABASE_URL -c "SELECT status, COUNT(*) FROM \"AIBatchRequest\" GROUP BY status;"
```

#### Database Issues
```bash
# Check database connection
pnpm db:check

# Verify schema integrity
pnpm migration:validate-db

# Check for missing indexes
psql $DATABASE_URL -c "
SELECT schemaname, tablename, indexname 
FROM pg_indexes 
WHERE tablename IN ('Session', 'AIProcessingRequest', 'AIBatchRequest')
ORDER BY tablename, indexname;
"
```

#### Environment Configuration Issues
```bash
# Validate environment variables
pnpm migration:validate-env

# Check for missing variables
env | grep -E "(TRPC|BATCH|RATE_LIMIT)" | sort

# Verify environment file syntax
node -e "require('dotenv').config({path: '.env.local'}); console.log('‚úÖ Environment file is valid')"
```

### Getting Help

#### Support Channels
1. **Check Migration Logs**: Review `logs/migration.log` for detailed error information
2. **Run Diagnostics**: Use the built-in health check and validation tools
3. **Documentation**: Refer to component-specific documentation in `docs/`
4. **Emergency Rollback**: Use rollback procedures if issues persist

#### Useful Commands
```bash
# Get detailed system information
pnpm migration:health-report

# Check all migration script availability
ls -la scripts/migration/

# Verify package integrity
pnpm install --frozen-lockfile

# Test database connectivity
pnpm prisma db pull --print
```

## üìù Post-Migration Tasks

### Immediate Tasks (First 24 Hours)
- [ ] Monitor application logs for errors
- [ ] Verify all tRPC endpoints are responding correctly
- [ ] Check batch processing job completion
- [ ] Validate AI cost reduction in OpenAI dashboard
- [ ] Run full test suite to ensure no regressions
- [ ] Update documentation and team knowledge

### Medium-term Tasks (First Week)
- [ ] Optimize batch processing parameters based on usage
- [ ] Fine-tune rate limiting settings
- [ ] Set up monitoring alerts for new components
- [ ] Train team on new tRPC APIs
- [ ] Plan gradual feature adoption

### Long-term Tasks (First Month)
- [ ] Analyze cost savings and performance improvements
- [ ] Consider additional tRPC endpoint implementations
- [ ] Optimize batch processing schedules
- [ ] Review and adjust security settings
- [ ] Plan next phase improvements

## üîí Security Considerations

### New Security Features
- **Enhanced Rate Limiting**: Applied to all authentication endpoints
- **Input Validation**: Comprehensive Zod schemas prevent injection attacks
- **Secure Headers**: HTTPS enforcement in production
- **Token Security**: JWT with proper expiration and rotation

### Security Checklist
- [ ] Verify rate limiting is working correctly
- [ ] Test input validation on all forms
- [ ] Ensure HTTPS is enforced in production
- [ ] Validate JWT token handling
- [ ] Check for proper error message sanitization
- [ ] Verify OpenAI API key is not exposed in logs

## üìà Expected Improvements

### Performance Improvements
- **50% reduction** in OpenAI API costs through batch processing
- **30% improvement** in API response times with tRPC
- **25% reduction** in database query time with new indexes
- **Enhanced scalability** for processing larger session volumes

### Developer Experience
- **Type Safety**: End-to-end TypeScript types from client to server
- **Better APIs**: Self-documenting tRPC procedures
- **Improved Testing**: More reliable test suite with better validation
- **Enhanced Monitoring**: Detailed health checks and reporting

### Operational Benefits
- **Automated Batch Processing**: Reduced manual intervention
- **Better Error Handling**: Comprehensive retry mechanisms
- **Improved Monitoring**: Real-time health status and metrics
- **Simplified Deployment**: Automated migration and rollback procedures

---

## üìû Support

For issues during migration:

1. **Check the logs**: `logs/migration.log`
2. **Run health checks**: `pnpm migration:health-check`
3. **Review troubleshooting section** above
4. **Use rollback if needed**: `pnpm migration:rollback`

**Migration completed successfully? üéâ**

Your LiveDash Node application is now running version 2.0.0 with tRPC and Batch API integration!

---
*Migration Guide v2.0.0 - Updated January 2025*